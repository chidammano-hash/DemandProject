# Feature 1D: Time Dimension (MVP)

## Purpose
Define a reusable calendar/time dimension for all domains (`item`, `location`, `customer`) and for daily/weekly/monthly/quarterly/yearly buckets.

## Table
`dim_time`

## Internal Keys
- `time_sk` (surrogate key)
- `time_ck` (same as `date_key`)

## Required Fields
- `date_key` (date)
- `day_name`
- `day_of_week` (ISO: Monday=1 ... Sunday=7)
- `day_of_month`
- `day_of_year`
- `iso_week_year`
- `iso_week`
- `week_start_date`
- `week_end_date`
- `month_number`
- `month_name`
- `month_start_date`
- `month_end_date`
- `quarter_number`
- `quarter_label`
- `quarter_start_date`
- `quarter_end_date`
- `year_number`
- `year_start_date`
- `year_end_date`
- `week_bucket` (`YYYY-Www`)
- `month_bucket` (`YYYY-MM`)
- `quarter_bucket` (`YYYY-Qn`)
- `year_bucket` (`YYYY`)
- `load_ts`
- `modified_ts`

## Generation Rules (Current Implementation)
- range: `2020-01-01` through `2035-12-31` (inclusive)
- one row per day
- `time_ck = date_key`
- week values use ISO calendar semantics
- ISO week-year can differ from calendar year near year boundaries
  - example: `2035-12-31` has `iso_week_year = 2036`

## Source Mapping (MVP)
No external source file.

Generated by:
- `mvp/demand/scripts/normalize_dataset_csv.py --dataset time`

Output:
- `mvp/demand/data/timedata_clean.csv`

## Usage in Pipeline
1. Generate calendar CSV (`normalize-time`)
2. Load to Postgres (`load-time`)
3. Publish to Iceberg (`spark-time`)
4. Query through API/UI:
   - `/domains/time`
   - `/domains/time/page`
   - `/times`
   - `/times/page`
   - `http://127.0.0.1:5173/?domain=time`
